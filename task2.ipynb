{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IML assignment 2\n",
    "### Import libraries and data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression, LassoCV\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import KNNImputer, SimpleImputer, IterativeImputer\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, VarianceThreshold\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn import linear_model\n",
    "\n",
    "def read_from_file(file):\n",
    "    df = pd.read_csv(file, header = 0)\n",
    "    return df._get_numeric_data().values\n",
    "\n",
    "train_features_file = \"train_features.csv\"\n",
    "train_labels_file = \"train_labels.csv\"\n",
    "output_file = \"submission.txt\"\n",
    "\n",
    "train_features = read_from_file(train_features_file)\n",
    "labels = read_from_file(train_labels_file)\n",
    "\n",
    "m = 12  # m = #hours per patient\n",
    "\n",
    "# Reduce data size for faster testing: (remove this for entire data set)\n",
    "#k = 1000\n",
    "#train_features = train_features[:k*12, :]\n",
    "#labels = labels[:k, :]\n",
    "\n",
    "n = labels.shape[0] # n = #patients\n",
    "\n",
    "X_2d = train_features.reshape(n, m, -1)[:, :, 2:]  # features represented as 3D n * m * d_x array\n",
    "d_x = X_2d.shape[2]  # d_x = #features per patient per hour\n",
    "\n",
    "X = X_2d[:, :, 1:].reshape(n, m * (d_x - 1))  # features represented as 2D n * m d_x array\n",
    "X = np.concatenate((X_2d[:, 0, 0].reshape(n, 1), X), axis=1)  # Add age feature seperately so that it is not repeated 12 times\n",
    "Y = labels[:, 1:]\n",
    "d_y = Y.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data impution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18995, 409)\n"
     ]
    }
   ],
   "source": [
    "# Data impution:\n",
    "#imputer = KNNImputer(n_neighbors=10, weights=\"uniform\")  # can also do weights=\"distance\"\n",
    "#imputer = IterativeImputer(max_iter=2, random_state=0)\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')  # this is a stupid strategy but KNN is too slow?\n",
    "X_imp = imputer.fit_transform(X)\n",
    "print(np.shape(X_imp))\n",
    "# This gives ok results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier removal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17855, 409)\n"
     ]
    }
   ],
   "source": [
    "#clf = EllipticEnvelope(contamination=0.05, random_state=0)\n",
    "#clf = IsolationForest(random_state=0, n_estimators=100)\n",
    "#clf.fit(X_imp)\n",
    "#print(\"fit done\")\n",
    "#scores_pred = clf.decision_function(X_imp)\n",
    "#y_pred = clf.predict(X_imp)\n",
    "#print(\"predict done\")\n",
    "\n",
    "clf = LocalOutlierFactor(n_neighbors=30, contamination=0.06)\n",
    "y_pred = clf.fit_predict(X_imp)\n",
    "X_inliers = X_imp[y_pred==1]\n",
    "Y_inliers = Y[y_pred==1]\n",
    "print(X_inliers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17855, 409)\n"
     ]
    }
   ],
   "source": [
    "selector = VarianceThreshold(threshold=1e-5)\n",
    "X_fs = selector.fit_transform(X_inliers)  # remove constant or low variance features\n",
    "print(X_fs.shape)\n",
    "\n",
    "# Could also try PCA to reduce feature space dimension?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_fs)\n",
    "#scaler = preprocessing.MinMaxScaler().fit(X_fs)\n",
    "#scaler = preprocessing.RobustScaler().fit(X_fs)\n",
    "X_std = scaler.transform(X_fs)\n",
    "# This also has a negative effect??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_file = \"test_features.csv\"\n",
    "test_features = read_from_file(test_features_file)\n",
    "X_test_ID = test_features[1:,0]\n",
    "X_test_ID = pd.unique(X_test_ID)\n",
    "n_test = test_features.shape[0] // m\n",
    "X_2d_test = test_features.reshape(n_test, m, -1)[:, :, 2:]\n",
    "X_test = X_2d_test[:, :, 1:].reshape(n_test, m * (d_x - 1))\n",
    "X_test = np.concatenate((X_2d_test[:, 0, 0].reshape(n_test, 1), X_test), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute and standardize test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_imp = imputer.transform(X_test)\n",
    "X_test_fs = selector.transform(X_test_imp)\n",
    "X_test_std = scaler.transform(X_test_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Subtask 1:\n",
    "Predict whether medical tests are ordered by a clinician in the remainder of the hospital stay: 0 means that there will be no further tests of this kind ordered, 1 means that at least one of a test of that kind will be ordered. In the submission file, you are asked to submit predictions in the interval [0, 1], i.e., the predictions are not restricted to binary. 0.0 indicates you are certain this test will not be ordered, 1.0 indicates you are sure it will be ordered. The corresponding columns containing the binary groundtruth in train_labels.csv are: LABEL_BaseExcess, LABEL_Fibrinogen, LABEL_AST, LABEL_Alkalinephos, LABEL_Bilirubin_total, LABEL_Lactate, LABEL_TroponinI, LABEL_SaO2, LABEL_Bilirubin_direct, LABEL_EtCO2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue: some patients do not start at hour 1, but 2, 3, 4 etc???\n",
    "C = 0.1  # Regularization parameter (inversely proportional, not lambda)\n",
    "clf = svm.SVC(C=C, kernel='rbf', gamma='scale', probability=False, class_weight='balanced')  # The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data\n",
    "#clf = RandomForestClassifier(n_estimators = 200, random_state=0, class_weight='balanced')\n",
    "\n",
    "# TODO: try prob=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV ROCAUC evaluation:\n",
    "rocauc = metrics.make_scorer(metrics.roc_auc_score)\n",
    "ROCAUCs = np.zeros(11)\n",
    "for i in range(0, 11):\n",
    "    X_kb = SelectKBest(f_classif, k=70).fit_transform(X_std, Y_inliers[:, i])\n",
    "    scores = cross_val_score(clf, X_kb, Y_inliers[:, i], cv=5, scoring=rocauc)\n",
    "    #print(\"ROCAUCs:\", scores)\n",
    "    print(\"Label\", i, \"mean ROCAUC:\", scores.mean())\n",
    "    ROCAUCs[i] = scores.mean()\n",
    "print(\"Mean ROCAUC:\", ROCAUCs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.80045432 0.70239864 0.72501394 ... 0.63443163 0.26750934 0.54794324]\n",
      " [0.28707682 0.26711066 0.57585069 ... 0.44960381 0.23866107 0.25548372]\n",
      " [0.53793091 0.26790986 0.28976933 ... 0.31645935 0.59845421 0.61336351]\n",
      " ...\n",
      " [0.71320879 0.28681696 0.28493361 ... 0.22858448 0.21529354 0.68641123]\n",
      " [0.72201026 0.70239026 0.72116483 ... 0.63444814 0.68461258 0.65754246]\n",
      " [0.59126655 0.28360103 0.25576601 ... 0.27278344 0.26376967 0.37866463]]\n"
     ]
    }
   ],
   "source": [
    "# Train, predict, print score:\n",
    "solution = 0.5*np.ones(np.shape(X_test_std[:,0:11]))\n",
    "\n",
    "for i in range(0, 11):\n",
    "    selector_kbest = SelectKBest(f_classif, k=70) \n",
    "    X_kb = selector_kbest.fit_transform(X_std, Y_inliers[:, i])\n",
    "    clf.fit(X_kb, Y_inliers[:, i])\n",
    "\n",
    "    X_test_std_kb = selector_kbest.transform(X_test_std)\n",
    "    sol = clf.decision_function(X_test_std_kb)\n",
    "    solution[:,i] = (1 + np.exp(-sol))**-1\n",
    "print(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification metrics:\n",
    "Y_pred = clf.predict(X_std)\n",
    "print(metrics.classification_report(Y_inliers[:, i], Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve:\n",
    "metrics.plot_roc_curve(clf, X_std, Y_inliers[:, 0]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask 2:\n",
    "Predict whether sepsis will occur in the remaining stay: 0 means that no sepsis will occur, 1 otherwise. Similar to Subtask 1, you are asked to produce predictions in the interval [0, 1] for this task. The corresponding column containing the binary groundtruth in train_labels.csv is LABEL_Sepsis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is this task different than the one before??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask 3:\n",
    "Predict future mean values of key vital signs. The corresponding columns containing the real-valued groundtruth in train_labels.csv are LABEL_RRate, LABEL_ABPm, LABEL_SpO2, LABEL_Heartrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 : 0.440162106878184 with alpha: 10000.0\n",
      "12 : 0.6169380139910634 with alpha: 1000.0\n",
      "13 : 0.38443789630200653 with alpha: 10000.0\n",
      "14 : 0.6627202584273062 with alpha: 1000.0\n"
     ]
    }
   ],
   "source": [
    "regcv = linear_model.RidgeCV(alphas=np.logspace(-6, 6, 13))\n",
    "#regcv = linear_model.LassoLarsCV()\n",
    "#regcv = linear_model.ElasticNetCV(cv=5)\n",
    "\n",
    "for i in range(11, 15):\n",
    "    regcv.fit(X_std, Y_inliers[:, i])\n",
    "    alpha = regcv.alpha_\n",
    "    \n",
    "    reg = linear_model.Ridge(alpha=alpha)\n",
    "    reg.fit(X_std, Y_inliers[:, i])\n",
    "    print(i, \":\", reg.score(X_std, Y_inliers[:, i]), \"with alpha:\", alpha)\n",
    "    sol = reg.predict(X_test_std)\n",
    "    \n",
    "    sol = np.reshape(sol,[np.size(sol),1])\n",
    "    solution = np.append(solution,sol,axis=1)\n",
    "\n",
    "#regcv = linear_model.MultiTaskElasticNetCV(cv=5, fit_intercept=False)\n",
    "#regcv = linear_model.MultiTaskLassoCV(cv=5, fit_intercept=False)\n",
    "\n",
    "#regcv.fit(X_std, Y_inliers[:, 11:14])\n",
    "#alpha = regcv.alpha_\n",
    "#sol = regcv.predict(X_test_std)\n",
    "#print(i, \":\", regcv.score(X_std, Y_inliers[:, 11:14]), \"with alpha:\", alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12664, 16)\n",
      "           pid  LABEL_BaseExcess  LABEL_Fibrinogen  LABEL_AST  \\\n",
      "0          0.0          0.800454          0.702399   0.725014   \n",
      "1      10001.0          0.287077          0.267111   0.575851   \n",
      "2      10003.0          0.537931          0.267910   0.289769   \n",
      "3      10004.0          0.276994          0.333672   0.642204   \n",
      "4      10005.0          0.269342          0.264597   0.276093   \n",
      "...        ...               ...               ...        ...   \n",
      "12659   9989.0          0.442807          0.516489   0.680539   \n",
      "12660   9991.0          0.455461          0.503629   0.285134   \n",
      "12661   9992.0          0.713209          0.286817   0.284934   \n",
      "12662   9994.0          0.722010          0.702390   0.721165   \n",
      "12663   9997.0          0.591267          0.283601   0.255766   \n",
      "\n",
      "       LABEL_Alkalinephos  LABEL_Bilirubin_total  LABEL_Lactate  \\\n",
      "0                0.725105               0.724846       0.667681   \n",
      "1                0.580399               0.581768       0.276370   \n",
      "2                0.278862               0.283115       0.729472   \n",
      "3                0.642617               0.625945       0.287232   \n",
      "4                0.277194               0.273172       0.269216   \n",
      "...                   ...                    ...            ...   \n",
      "12659            0.671507               0.684543       0.313641   \n",
      "12660            0.304118               0.281716       0.337193   \n",
      "12661            0.303868               0.281075       0.611484   \n",
      "12662            0.721463               0.722798       0.724276   \n",
      "12663            0.256384               0.259141       0.464873   \n",
      "\n",
      "       LABEL_TroponinI  LABEL_SaO2  LABEL_Bilirubin_direct  LABEL_EtCO2  \\\n",
      "0             0.373574    0.690065                0.634432     0.267509   \n",
      "1             0.476558    0.335061                0.449604     0.238661   \n",
      "2             0.460387    0.715894                0.316459     0.598454   \n",
      "3             0.352282    0.268724                0.611695     0.260228   \n",
      "4             0.292013    0.249944                0.267613     0.212090   \n",
      "...                ...         ...                     ...          ...   \n",
      "12659         0.234515    0.298961                0.343616     0.274616   \n",
      "12660         0.315743    0.275016                0.365675     0.294485   \n",
      "12661         0.213895    0.682058                0.228584     0.215294   \n",
      "12662         0.330826    0.720963                0.634448     0.684613   \n",
      "12663         0.205998    0.519834                0.272783     0.263770   \n",
      "\n",
      "       LABEL_Sepsis  LABEL_RRate  LABEL_ABPm  LABEL_SpO2  LABEL_Heartrate  \n",
      "0          0.547943    14.678967   84.254526   98.154471        82.822211  \n",
      "1          0.255484    18.490010   87.346970   95.096721        98.494288  \n",
      "2          0.613364    17.365598   81.747872   97.938812        89.366555  \n",
      "3          0.300056    16.870876   74.074324   95.607958        87.784192  \n",
      "4          0.300272    19.338788   75.430370   95.731384        60.527054  \n",
      "...             ...          ...         ...         ...              ...  \n",
      "12659      0.534691    20.575601   78.801485   95.513097       100.801863  \n",
      "12660      0.355560    18.412694   90.896367   98.417214        74.673173  \n",
      "12661      0.686411    18.773945   66.587401   97.206180        82.417613  \n",
      "12662      0.657542    17.515281   93.506244  101.973106       101.610705  \n",
      "12663      0.378665    17.539882   76.887498   98.303576        86.647006  \n",
      "\n",
      "[12664 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "solution = np.fliplr(solution)\n",
    "X_test_ID = np.reshape(X_test_ID,[len(X_test_ID),1])\n",
    "solution = np.append(solution,X_test_ID,axis=1)\n",
    "solution = np.fliplr(solution)\n",
    "print(solution.shape)\n",
    "df = pd.DataFrame(solution, columns = ['pid','LABEL_BaseExcess','LABEL_Fibrinogen','LABEL_AST','LABEL_Alkalinephos','LABEL_Bilirubin_total','LABEL_Lactate','LABEL_TroponinI','LABEL_SaO2','LABEL_Bilirubin_direct','LABEL_EtCO2','LABEL_Sepsis','LABEL_RRate','LABEL_ABPm','LABEL_SpO2','LABEL_Heartrate'])\n",
    "df.to_csv('prediction.zip', index=False, float_format='%.3f', compression='zip')\n",
    "np.savetxt(output_file, df, fmt='%.10f')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
